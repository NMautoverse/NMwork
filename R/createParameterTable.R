##' Create parameter table data.frame using `NMreadExt()` and
##' `NMreadParsText()`
##'
##' Automated parameter table creation of Nonmem models. Currently,
##' requires a covariance step.
##' 
##' @param file.lst Control stream. If possible, it is recommended to
##'     use output control stream. You can also use input control
##'     stream.
##' @param args.ParsText List of arguments to be passes to
##'     `NMreadParsText()`. This will only be used if `df.labs` is
##'     omitted.
##' @param df.repair Optional table of labels to overwrite results
##'     from `NMreadParsText()`. Useful to correct table issues
##'     without rerunning the model. This is only relevant if df.labs
##'     is omitted, and `NMreadParsText()` is run by
##'     `createParameterTable()`. Notice, the `df.labs` argument
##'     provides full flexibility to construct the labels before
##'     running `createParameterTable()`, and `dt.labels` is only a
##'     solution to a more specific case. `dt.labels` is likely to be
##'     re-designed or even dropped in the future.
##' @param by.repair If `dt.labels` provided, names of columns to
##'     merge by.
##' @param df.labs An optional data.frame with parameter labels. If
##'     provided, this will be the only source of labels and other
##'     columns like units, transformations, etc. 
##' @param drop.symbol Symbol values to not include. To be specific,
##'     rows with these values in the symbol column will be omitted in
##'     the generated table.
##' @details The following columns are attempted used and may be
##'     modified. It is important for the user to understand how these
##'     must be formatted.
##'
##' In many cases, a combination of args.ParsText and
##' df.repair+by.repair is an easy way to have createParameterTable()
##' do all the work. This will use NMreadParsText() and mergeCoal() to
##' repair the table. If this is insufficient, the labels can be read
##' into a data.frame first and passed as \code{df.labs}. In that
##' case, other tools like NMrelate() can also be used.
##'
##' \code{createParameterTable} looks for and uses the following columns as available:
##' \itemize{
##' \item symbol Typically, the variable name associated with the parameter. "CL".
##' \item label The parameter label. "Clearance".
##' \item trans Parameter transformation (character strings). See below for possible strings.
##' \item unit The parameter unit. "L/h".
##' \item panel Blocks of parameters types. See below for options.
##' }
##'
##' Adding rse, CI.l, CI.u, and corr
##'
##' Descriptive columns generated by \code{createParameterTable}:
##' \itemize{
##'
##' \item tab.est The value column to be shown in parameter
##' tables. The format depends on the parameter type and the
##' transformation. 
##'
##' \item tab.est.ltx A latex version of tab.est
##'
##' \item parameter.ltx. A latex version of the
##' parameter name (like theta(1)). In case a THETA is log tranformed, an asterisk
##' (*) is appended, for logit transformed THETAs, two asterisks (**)
##' are appended. This is for footnoteing that the parameter estimates
##' are shown on the physiologigical or natural scale.
##' }
##' 
##' ### Guideline for panel column:
##'    ## THETA: struct (default), cov (covariates), RV (residual variability parameters)
##'    ## OMEGA: IIV/BSV (default), IOV/BOV
##'    ## OMEGA off diag: (handled automatically)
##'    ## SIGMA: (handled automatically)
##'
##' trans is used for the following:
##'
##' - Transformation: Model parameters (say THETA(1)) values and CI
##' to the scale of the interpretable parameter, (say CL).
##'
##' - Formatting: For Theta's trans equalling addErr and propErr gives formatting as residual standard
##' deviations for additive and proportional error terms,
##' respectively. 
##' 
##' 
##' ### trans column:
##'    ## THETA: none (default), log/logTrans, logit, addErr/SD, propErr/CV
##'    ## OMEGA: lognormal (default), normal
##'    ## OMEGA off diag: (handled automatically)
##'    ## SIGMA: Not implemented.
##'
##' ##' For THETAs
##' Inverse of log (inverse is exp) and logit (NMcalc::invlogit) will
##' be applied to parameter values and confidence intervals. SE and
##' RSE are calculated before the backtransformation and must be
##' interpreted on the scale of the estimated THETA, not the scale of
##' the transformed parameter (e.g. Clerance when CL=EXP(THETA+...).
##'
##' On OMEGA's, the lognormal distribut is for
##' CL=EXP(THETA +ETA) , normal is for additive effects:
##' PAR=EXP(THETA) + ETA.
##' 
##' Formatting of CV for OMEGAs
##' trans="normal" or "none": CV=se/est
##' trans="lognormal" : CV=sqrt(exp(OMEGA[i,i])-1)
##'
##'
##' SIGMA's are sorted and grouped as residual error terms, but
##' specific formatting of additive, proportional or exponential is
##' missing. Estimates reported are of the variances and
##' correlations.
##'
##'
##' \strong{Off-diagonals in OMEGA and SIGMA}
##' 
##' These should be fully automated. They are automatically
##' identified, and labels should be auto-generated based on labels of
##' the associated diagonal elements. I don't think the labeling is
##' implemented yet, but it should be relatively simple.
##'
##' Off-diagonal estimates are shown as correlations. But
##' SE is standard error of the variances or
##' cov-variances. For off-diagonal elements, the scale of the
##' estimate (correlation) and the scale of the associated uncertainty
##' (covariance) are different.
##'
##' \strong{Columns created by createParameterTable}
##'
##' tab.lab I proposed descriptive label for the parameter. Combines
##' label, (only for structural thetas) symbol and unit.
##'
##' panel.label
##' 
##' Latex versions (.ltx columns) are generated using
##' dplR::latexify. Because dplR is not included in MPN, and we need
##' just that one function from dplR, the function has been copied
##' into NMwork instead.
##' 
##' @import data.table
##' @import NMdata
##' @import stringi
##' @importFrom scales percent
##' @importFrom stats cov2cor
##' @export
##' @seealso formatParameterTable

### should also take arg to include fixed parameters. Maybe default
### should be estimated and non-zero?

createParameterTable <- function(file.lst,args.ParsText=NULL,df.repair=NULL,by.repair="symbol",df.labs,drop.symbol,file.ext,df.panels,script=NULL){
### If NMcalc version < 0.0.3 we need to define CVlnorm
    CVlnorm <- function(omega){
        sqrt(exp(omega)-1)
    }
    invlogit <- function(x) 1/(1+exp(-x))

    if(missing(drop.symbol)) drop.symbol <- NULL
    if(missing(file.ext)) file.ext <- file.lst
    if(missing(df.labs)) df.labs <- NULL
    

### parameters are assumed to be concistently labeled in $THETA,
### $OMEGA and $SIGMA sections

### Off-diagonal elements are automatically identified by NMreadParsText().
    
    pars <- NMreadExt(file=file.ext,as.fun="data.table")
    
    if(is.null(df.labs)){
        labs <- do.call(NMreadParsText,
                        as.list(c(args.ParsText,file=file.lst,as.fun="data.table"))
                        )
    } else {
        labs <- df.labs
    }
    
    ## dropping model from labs. Since the parameter estimates are
    ## coming from NMreadExt, it seems more accurate to carry the
    ## model name over from there.
    labs[,setdiff(colnames(labs),"model"),with=FALSE]
    
    ## we need a pars with anything found in labels, plus estimated omega and sigma off-diags
    pars.found <- merge(
        pars
       ,
        labs[,.(parameter)]
       ,by="parameter",all.y=TRUE)
    pars <- pars[parameter%in%pars.found[,parameter]|(FIX==0 & i!=j)]
    ## only for debugging
    pars0 <- copy(pars)

    
    
    ## compareCols(pars0,labs)
    pars <- mergeCheck(
        pars0
       ,
        labs[,!(c("i","j","par.type"))]
       ,by=intersect(intersect(colnames(pars0),colnames(labs)),cc(parameter)),
        all.x=T,
        ## common.cols="merge.by"
        common.cols="drop.y"
       ,as.fun="data.table"
       ,quiet=TRUE
    )
    
##### group parameters

#### guideline todo: How to define sigmas?
    
### Guideline for panel column:
    ## THETA: struct (default), cov, RV
    ## OMEGA: IIV/BSV (default), IOV/BOV
    ## OMEGA off diag: (handled automatically)
    
### trans:
    ## THETA: none (default), log, logit, addErr/SD, propErr/CV
    ## OMEGA: lognormal (default), normal
    ## OMEGA: off diag: (handled automatically)
    
    if(!"panel"%in%colnames(pars)) pars[,panel:=NA_character_]
    ## if(!"panel"%in%colnames(pars)) pars[,panel:=par.type]
    pars[is.na(panel)&par.type=="THETA",panel:="FixedEff"]
    ## pars[par.type=="THETA"&trans%in%cc(addErr,propErr),parGRP:="resVar"]
    ## pars[par.type=="THETA"&symbol%in%cc(ADDP,ADDM,PROPP,PROPM),parGRP:="resVar"]
    
    pars[is.na(panel)&par.type=="OMEGA"&i==j,panel:="IIV"]
    pars[par.type=="OMEGA"&panel=="BSV",panel:="IIV"]
    pars[par.type=="OMEGA"&panel=="BOV",panel:="IOV"]
    pars[is.na(panel)&par.type=="OMEGA"&i!=j,panel:="OMEGAcorr"]

    pars[is.na(panel)&par.type=="SIGMA"&i==j,panel:="resvar"]
    pars[is.na(panel)&par.type=="SIGMA"&i!=j,panel:="SIGMAcorr"]

    pars[tolower(panel)%in%cc(rv,resvar),panel:="resvar"]

### TODO: do we want to generate a factor with the observed values, guessing an order?
    ## pars[,panel:=factor(parGRP,levels=cc(theta,OMEGAdiag,OMEGAcorr,resVar))]
    
### This automates the labeling of the parameter blocks.
    dt.panels.std <- fread(text="panel,panel.label
FixedEff,Fixed Effects
Struct,Structural Parameters
Cov,Covariate Effects
IIV,Inter-Individual Variances
OMEGAcorr,Inter-Individual Covariances
IOV,Inter-Occasion Variances
resvar,Residual Error")

    if(missing(df.panels)) df.panels <- NULL
    if(!is.null(df.panels)) df.panels <- as.data.table(df.panels)

    df.panels <- rbind(df.panels,dt.panels.std)
    ## this unique is case-sensitive so df.panels$panel will have to
    ## match dt.panels.std$panel exactly to overwrite it.
    df.panels <- unique(df.panels,by="panel")

    ### align case of panel column with df.panels
    if("panel"%in%colnames(pars)){
        
        col.pold <- tmpcol(pars,base="panelold")
        col.pl <- tmpcol(pars,base="panellow")
        pars[,(col.pl):=tolower(panel)]
        setnames(pars,"panel",col.pold)
        ## setnames(pars,"panel",col.pold)
        pars <- mergeCheck(pars,df.panels[,.(panellow=tolower(panel),panel)],
                           by.x=col.pl,by.y="panellow",all.x=TRUE,
                           quiet=TRUE)
        pars[,panel:=fcoalesce(panel,get(col.pold))]
        pars[,(col.pold):=NULL]
        pars[,(col.pl):=NULL]
    }
    
    pars <- mergeCoal(pars,df.panels,by="panel",as.fun="data.table")
### if not matched with label, just use panel code
    pars[,panel.label:=fcoalesce(panel.label,panel)]

    
### this puts non-specified panels last. Maybe panel levels with thetas only should come earlier
    pars[,panel:=factor(panel,levels=c(df.panels[,panel],setdiff(panel,df.panels[,panel])))]
    ## pars[,panel.label:=factor(panel.label,levels=df.panels[,panel])]
    pars[,panel.label:=reorder(panel.label,as.numeric(panel))]
    setorder(pars,panel)

    setorder(pars,panel)

    if(!is.null(df.repair)){
        pars <- mergeCoal(x=pars,y=df.repair,by=by.repair,as.fun="data.table")
    }

    
#### requires a covariance step
    if("se"%in%colnames(pars)){
        pars[,rse:=abs(se/est)]
        pars[,CI.l:=est-1.96*se]
        pars[,CI.u:=est+1.96*se]
        pars[FIX==1,(cc(rse,CI.l,CI.u)):=NA]
    }

    ## est.orig is the estimate on the scale used in Nonmem
    pars[,est.orig:=est]
    ## back transform parameters estimated on a transformed scale
    ##pars[,.N,.(par.type,trans)]

    
    
    ## correlation between omegas
    if(nrow(pars[par.type=="OMEGA"])){
        Sigma <- dt2mat(pars[par.type=="OMEGA"])
        ## Sigma <- NMdata::dt2mat(pars[par.type=="OMEGA"])
        ## Sigma[is.na(Sigma),Sigma:=0]
        mat.cor <- suppressWarnings(cov2cor(Sigma))
        dt.cor <- as.data.table(mat.cor)
        dt.cor[,i:=.I]
        dt.cor <- melt(dt.cor,id.vars="i",variable.name="j")
        dt.cor[,j:=as.numeric(j)]
        dt.cor <- dt.cor[j<=i]
        ## pars <- mergeCheck(pars,dt.cor[,.(par.type="OMEGA",i,j,tab.corr=round(value))],by=cc(par.type,i,j),all.x=TRUE)

        pars <- mergeCheck(pars,dt.cor[,.(par.type="OMEGA",i,j,corr=value)],by=cc(par.type,i,j),all.x=TRUE,quiet=T,as.fun="data.table")
    } else {
        if(!"corr"%in%colnames(pars)){
            pars[,corr:=NA_real_]
        }
    }

###### patching/standardizing trans
    if(!"trans"%in%colnames(pars)){
        pars[,trans:=NA_character_]
    }
    pars[par.type=="THETA"&is.na(trans),trans:="none"]
    pars[par.type=="THETA"&trans=="logTrans",trans:="log"]
    pars[par.type=="THETA"&tolower(trans)=="SD",trans:="addErr"]
    pars[par.type=="THETA"&tolower(trans)=="CV",trans:="propErr"]
    pars[par.type=="OMEGA"&i==j&is.na(trans),trans:="lognormal"]
    pars[par.type=="OMEGA"&trans=="lognormalOm",trans:="lognormal"]
#### trans done

### unit
    if(!"unit"%in%colnames(pars)){
        pars[,unit:=""]
    }
    ## if unit is empty, use NA
    pars[grepl("^ *-* *$",unit),unit:=NA]
### 

    
### tab.lab is the formatted string (not latex) to show in a table
    
    if(!"label"%in%colnames(pars)){
        pars[,label:=NA_character_]
    }
    pars[,tab.lab:=label]
    
    if("symbol"%in%colnames(pars)){
        pars[,tab.lab:=fcoalesce(tab.lab,symbol)]
    }
    pars[is.na(tab.lab),tab.lab:=""]

    
    pars[par.type=="OMEGA"&trans=="normal",tab.lab:=paste(tab.lab,"(additive)")]

    ## pars[par.type=="THETA"&panel!="cov"&!is.na(label)&!is.na(symbol),tab.lab:=paste(label,symbol,sep=", ")]
    pars[par.type=="THETA"&!is.na(label)&!is.na(symbol),tab.lab:=paste(label,symbol,sep=", ")]
    pars[!is.na(unit),tab.lab:=sprintf("%s (%s)",ifelse(is.na(tab.lab),NA_character_,tab.lab),unit)]

### tab.lab done

    


### tab.lab done

####### Creating additional columns related to rse, correlation of omegas/sigmas
    if("rse"%in%colnames(pars)){
        pars[,tab.rse:=percent(rse,accuracy=.1)]
        pars[FIX==1,tab.rse:="-"]
    } else {
        pars[,tab.rse:="-"]
    }

    pars[panel=="OMEGAcorr",tab.corr:=percent(corr,accuracy=1)]
    pars[panel=="SIGMAcorr",tab.corr:=percent(corr,accuracy=1)]

### transformed values for reporting
### do not transform se or rse
    cols.trans <- intersect(cc(est,CI.l,CI.u),colnames(pars))
    pars[trans%in%cc(log,logTrans),(cols.trans):=lapply(.SD,exp),.SDcols=cols.trans]
    pars[trans%in%cc(logit),(cols.trans):=lapply(.SD,invlogit),.SDcols=cols.trans]
    
    pars[par.type=="THETA",tab.est:=sprintf("%s (%s)",signif(est,3),tab.rse)]
    ## pars[par.type=="THETA"&FIX==1,tab.est:=sprintf("%s (fixed)",signif(est,3))]
    pars[FIX!=0,tab.est:=sprintf("%s (fixed)",signif(est,3))]
    pars[par.type=="OMEGA"&trans=="lognormal"&FIX==0,tab.CV:=percent(CVlnorm(est),acc=1)]
    pars[par.type=="OMEGA"&trans=="lognormal"&FIX==0,tab.est:=sprintf("%s [%s] (%s)",signif(est,3),tab.CV,tab.rse)]

    ## for this, the associated theta est has to be used to calc CV
    ## pars[panel=="OMEGAdiag"&trans=="normal",tab.CV:=percent(sd/est,acc=1)]
    ## pars[panel=="OMEGAdiag"&trans=="normal",tab.est:=sprintf("%s [%s] (%s)",signif(est,3),tab.CV,tab.rse)]
    pars[par.type=="OMEGA"&trans=="normal"&FIX==0,tab.est:=sprintf("%s (%s)",signif(est,3),tab.rse)]
    ##    pars[panel=="OMEGAdiag"&is.na(label),tab.lab:=paste("BSV",symbol)]

    
    pars[panel=="OMEGAcorr"&FIX==0,tab.est:=sprintf("%s [%s] (%s)",signif(est,3),tab.corr,tab.rse)]


    if(all(cc(CI.l,CI.u)%in%colnames(pars))){
        pars[,CI:=sprintf("[%s,%s]",signif(CI.l,2),signif(CI.u,2))]
        pars[FIX==1,CI:="-"]
    } else {
        pars[,CI:="-"]
    }
    ## residual error terms
    pars[par.type=="THETA"&trans=="addErr",tab.est:=sprintf("%s (%s)",signif(est,3),tab.rse)]
    pars[par.type=="THETA"&trans=="propErr",tab.est:=sprintf("%s (%s)",percent(est,acc=1.1),tab.rse)]
    
    pars[par.type=="SIGMA"&FIX==0,tab.est:=sprintf("%s (%s)",signif(est,3),tab.rse)]
    pars[par.type=="SIGMA"&trans=="propErr"&FIX==0,
         tab.est:=sprintf("%s [%s] (%s)",est,percent(sqrt(est),acc=1.1),tab.rse)]
    
    ## Latex versions of columns for report tables
    pars[,tab.est.ltx:=latexify(tab.est,doublebackslash = FALSE)]
    pars[,tab.lab.ltx:=latexify(tab.lab,doublebackslash = FALSE)]
    pars[par.type=="THETA",parameter.ltx:=paste0("$\\theta_{",i,"}$")]
    pars[par.type=="OMEGA",parameter.ltx:=paste0("$\\Omega_{",i,",",j,"}$")]
    pars[par.type=="SIGMA",parameter.ltx:=paste0("$\\sigma_{",i,",",j,"}$")]

### Include * at log-transformed variables
    ## pars[par.type=="THETA"&trans%in%c("log"),parameter.ltx:=sub("\\$ *$","\\{\\}\\^\\*\\$",parameter.ltx)]
### Include * at logit-transformed variables
    ## pars[par.type=="THETA"&trans%in%c("logit"),parameter.ltx:=sub("\\$ *$","\\{\\}\\^\\{\\*\\*\\}\\$",parameter.ltx)]

    
    if(!is.null(drop.symbol)){
        if(!"symbol"%in%colnames(pars)){
            warning("drop.symbol provied but column symbol is not found in table. drop.symbol not used.")
            drop.symbol <- NULL
        }
        if(!is.null(drop.symbol)){
            pars <- pars[!grepl(pattern=drop.symbol,symbol)]
        }
    }

    
    NMstamp(pars,script
            =script$label,model=file.lst)
    pars[]


}


